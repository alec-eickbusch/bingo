{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 16:58:25.935429: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-26 16:58:26.011159: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Need tf version 2.3.0 or later. Using tensorflow version: 2.10.0\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'QOGS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mqutip\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mqt\u001b[39;00m \n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbingo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_adam_optimizer\u001b[39;00m \u001b[39mimport\u001b[39;00m AdamOptimizer\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbingo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgate_sets\u001b[39;00m \u001b[39mimport\u001b[39;00m ECDGateSet\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbingo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGateSynthesizer\u001b[39;00m \u001b[39mimport\u001b[39;00m GateSynthesizer\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/bingo/gate_sets/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mQOGS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgate_sets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgate_set\u001b[39;00m \u001b[39mimport\u001b[39;00m GateSet\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mQOGS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgate_sets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mECD_gate_set\u001b[39;00m \u001b[39mimport\u001b[39;00m ECDGateSet\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mQOGS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgate_sets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSNAP\u001b[39;00m \u001b[39mimport\u001b[39;00m SNAP\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'QOGS'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import qutip as qt \n",
    "from bingo.optimizer.tf_adam_optimizer import AdamOptimizer\n",
    "from bingo.gate_sets import ECDGateSet\n",
    "from bingo.optimizer.GateSynthesizer import GateSynthesizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization of ECD Circuit parameters (betas, phis, and thetas)\n",
    "N = 40\n",
    "# We initialize the ECDGateSet here\n",
    "gate_set_params = {\n",
    "    'N_cav' : N,\n",
    "    'beta_scale' : 1.0, #maximum |beta| for random initialization  \n",
    "}\n",
    "ECD_gate_set = ECDGateSet(**gate_set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The target oscillator state.\n",
    "fock = 1\n",
    "psi_t = qt.basis(N,fock) #target state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the optimization options\n",
    "synth_params = {\n",
    "    'gateset' : ECD_gate_set,\n",
    "    'N_blocks':6,\n",
    "    'N_multistart' : 100, #Batch size (number of circuit optimizations to run in parallel)\n",
    "    'epochs' : 100, #number of epochs before termination\n",
    "    'epoch_size' : 10, #number of adam steps per epoch\n",
    "    'learning_rate' : 0.01, #adam learning rate\n",
    "    'term_fid' : 0.995, #terminal fidelitiy\n",
    "    'dfid_stop' : 1e-6, #stop if dfid between two epochs is smaller than this number\n",
    "    'beta_scale' : 3.0, #maximum |beta| for random initialization\n",
    "    'initial_states' : [qt.tensor(qt.basis(2,0),qt.basis(N,0))], #qubit tensor oscillator, start in |g> |0>\n",
    "    'target_states' : [qt.tensor(qt.basis(2,1), psi_t)], #end in |e> |target>.\n",
    "    'name' : 'Fock %d' % fock, #name for printing and saving\n",
    "    'filename' : None, #if no filename specified, results will be saved in this folder under 'name.h5'\n",
    "}\n",
    "gatesynth = GateSynthesizer(**synth_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_blocks: 6\n",
      "optimization_type: state transfer\n",
      "optimization_masks: {'betas_rho': None, 'betas_angle': None, 'phis': None, 'etas': None, 'thetas': None}\n",
      "target_unitary: None\n",
      "expectation_operators: None\n",
      "target_expectation_values: None\n",
      "N_multistart: 100\n",
      "term_fid: 0.995\n",
      "dfid_stop: 1e-06\n",
      "learning_rate: 0.01\n",
      "epoch_size: 10\n",
      "epochs: 100\n",
      "name: Fock 1\n",
      "filename: None\n",
      "comment: \n",
      "coherent: False\n",
      "timestamps: []\n",
      "do_prints: True\n",
      "beta_scale: 3.0\n",
      "filename: Fock 1.h5\n",
      "\n",
      "Best circuit parameters found:\n",
      "betas:    tf.Tensor(\n",
      "[-0.1643 -2.58888j -0.00317-0.01064j  0.61617+1.92017j -1.49207+0.83361j\n",
      " -1.00905+2.67741j -0.71373+0.81384j], shape=(6,), dtype=complex64)\n",
      "phis:    tf.Tensor([ 0.0165   1.05139 -1.51982  1.74225 -3.06771 -1.32724], shape=(6,), dtype=float32)\n",
      "etas:    tf.Tensor([ 3.08698  2.05205 -0.21682 -2.06456 -3.05512  1.13359], shape=(6,), dtype=float32)\n",
      "thetas:    tf.Tensor([-2.77055  0.33222  2.23685  0.08906 -1.85906  3.07291], shape=(6,), dtype=float32)\n",
      "\n",
      " Best circuit Fidelity: 0.286582\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create optimization object. \n",
    "#initial params will be randomized upon creation\n",
    "opt = AdamOptimizer(gatesynth)\n",
    "\n",
    "#print optimization info. this lives in gatesynth, since we eventually want to fully abstract away the optimizer\n",
    "gatesynth.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2022-09-09 19:50:36\n",
      " Epoch: 9 / 100 Max Fid: 0.997844 Avg Fid: 0.815547 Max dFid: 0.156950 Avg dFid: 0.046593 Elapsed time: 0:00:02.893301 Expected remaining time: 0:00:29.254493\n",
      "\n",
      " Optimization stopped. Term fidelity reached.\n",
      "\n",
      "N_blocks: 6\n",
      "optimization_type: state transfer\n",
      "optimization_masks: {'betas_rho': None, 'betas_angle': None, 'phis': None, 'etas': None, 'thetas': None}\n",
      "target_unitary: None\n",
      "expectation_operators: None\n",
      "target_expectation_values: None\n",
      "N_multistart: 100\n",
      "term_fid: 0.995\n",
      "dfid_stop: 1e-06\n",
      "learning_rate: 0.01\n",
      "epoch_size: 10\n",
      "epochs: 100\n",
      "name: Fock 1\n",
      "filename: None\n",
      "comment: \n",
      "coherent: False\n",
      "timestamps: ['2022-09-09 19:50:36']\n",
      "do_prints: True\n",
      "beta_scale: 3.0\n",
      "filename: Fock 1.h5\n",
      "\n",
      "Best circuit parameters found:\n",
      "betas:    tf.Tensor(\n",
      "[-0.58016-1.07921j -0.4053 +0.68378j  0.72741+0.43834j  0.07378+0.38559j\n",
      " -0.03577+0.91321j  0.04455+0.8253j ], shape=(6,), dtype=complex64)\n",
      "phis:    tf.Tensor([-0.99996 -2.62713  1.5283   2.32521  0.96461 -1.78703], shape=(6,), dtype=float32)\n",
      "etas:    tf.Tensor([ 1.24726 -2.51909 -2.54491 -2.36975 -0.83806  0.66394], shape=(6,), dtype=float32)\n",
      "thetas:    tf.Tensor([-1.60687  2.95901  1.67837 -2.32521 -1.75901 -0.51594], shape=(6,), dtype=float32)\n",
      "\n",
      " Best circuit Fidelity: 0.998108\n",
      "\n",
      "\n",
      "all data saved as: Fock 1.h5\n",
      "termination reason: term_fid\n",
      "optimization timestamp (start time): 2022-09-09 19:50:36\n",
      "timestamp (end time): 2022-09-09 19:50:39\n",
      "elapsed time: 0:00:02.901175\n",
      "Time per epoch (epoch size = 10): 0:00:00.322353\n",
      "Time per Adam step (N_multistart = 100): 0:00:00.003224\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2022-09-09 19:50:36'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run optimizer.\n",
    "#note the optimizer can be stopped at any time by interrupting the python consle,\n",
    "#and the optimization results will still be saved and part of the opt object.\n",
    "#This allows you to stop the optimization whenever you want and still use the result.\n",
    "opt.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can print info, including the best circuit found.\n",
    "gatesynth.print_info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gatesynth.best_fidelity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can also get the best circuit parameters directly, could save this to a .npz file.\n",
    "best_circuit =  gatesynth.best_circuit()\n",
    "betas = best_circuit['betas']\n",
    "phis = best_circuit['phis']\n",
    "thetas = best_circuit['thetas']\n",
    "print(best_circuit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
